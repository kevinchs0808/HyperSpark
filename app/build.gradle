/*
 * This file was generated by the Gradle 'init' task.
 *
 * This generated file contains a sample Scala application project to get you started.
 * For more details on building Java & JVM projects, please refer to https://docs.gradle.org/8.5/userguide/building_java_projects.html in the Gradle documentation.
 */

plugins {
    // Apply the scala Plugin to add support for Scala.
    id 'scala'

    // Apply the application plugin to add support for building a CLI application in Java.
    id 'application'
}

applicationDefaultJvmArgs = [
        '--add-exports', 'java.base/sun.nio.ch=ALL-UNNAMED'
]


repositories {
    // Use Maven Central for resolving dependencies.
    mavenCentral()
}

dependencies {

    // Use Scala 2.13 in our library project
    implementation 'org.scala-lang:scala-library:2.13.11'

    // This dependency is used by the application.
    implementation libs.guava
    implementation 'org.apache.spark:spark-core_2.13:3.5.0'
    implementation 'org.apache.spark:spark-sql_2.13:3.5.0'
    implementation 'org.apache.spark:spark-mllib_2.13:3.5.0'
    implementation 'org.ow2.asm:asm:9.5'

    // Use Scalatest for testing our library
    testImplementation libs.junit
    testImplementation libs.scalatest.v2.v13
    testImplementation libs.junit.v4.v13.v2.v13

    // Need scala-xml at test runtime
    testRuntimeOnly libs.scala.xml.v2.v13
}

// Apply a specific Java toolchain to ease working on different environments.
java {
    toolchain {
        languageVersion = JavaLanguageVersion.of(21)
    }
}

application {
    // Define the main class for the application.
    mainClass = 'hyperspark.App'
}

task runSparkHDFS(type: JavaExec) {
    main = 'hyperspark.App'

    // Set HADOOP_CONF_DIR environment variable
    doLast {
        environment 'HADOOP_CONF_DIR', project.hasProperty('HADOOP_CONF_DIR') ? project.HADOOP_CONF_DIR : ''
    }
}